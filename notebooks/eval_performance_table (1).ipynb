{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d447a517-1796-402b-a708-0637d1729dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nravindra/miniconda3/envs/scnd2/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tqdm\n",
    "import os \n",
    "import glob \n",
    "import sys\n",
    "sys.path.append('/home/ngr4/project/edge_feat/scripts')\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import utils\n",
    "# import load_data as data\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torch_geometric.nn import GCNConv\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import coo_matrix\n",
    "# import graphtools as gt\n",
    "# import phate\n",
    "# import umap\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "import scanpy as sc\n",
    "from scipy import sparse\n",
    "# import scprep\n",
    "import time\n",
    "import datetime\n",
    "from scipy.stats import zscore\n",
    "from adjustText import adjust_text\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from captum.attr import (\n",
    "#     GradientShap,\n",
    "#     DeepLift,\n",
    "#     DeepLiftShap,\n",
    "    IntegratedGradients,\n",
    "#     LayerConductance,\n",
    "#     NeuronConductance,\n",
    "    NoiseTunnel,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "plt.rc('font', size = 8)\n",
    "plt.rc('font', family='sans serif')\n",
    "plt.rcParams['pdf.fonttype']=42\n",
    "plt.rcParams['ps.fonttype']=42\n",
    "plt.rcParams['legend.frameon']=False\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac8c4610-26a5-4582-a7e7-c4ec11a0cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/nravindra/project/')\n",
    "from scnd.scripts import scgat_pipeline_dev as scgat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d58af281-6ec6-4e94-bff2-72aa2b24e9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting eval...\n",
      "/home/nravindra/project/scnd/scripts/scgat_pipeline_dev.py:44: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755897462/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  indices=torch.LongTensor([coo_data.row, coo_data.col]) # OR transpose list of index tuples\n",
      "Computing METIS partitioning...\n",
      "Done!\n",
      "100%|███████████████████████████████████████████| 20/20 [00:02<00:00,  8.09it/s]\n",
      "\n",
      "Test set eval:\n",
      "  <loss>mb: 0.1502\n",
      "  <acc >mb: 0.9420\n",
      "\n",
      "SCA1_5wk results\n",
      "-----------------------\n",
      "Accuracy      : 0.8472\n",
      "Sensitivity   : 0.8235\n",
      "Specificity   : 0.8506\n",
      "\n",
      "Ave. precision: 0.3537\n",
      "Precision     : 0.9369\n",
      "Recall        : 1.0000\n",
      "\n",
      "AU-ROC        : 0.9046\n",
      "AU-PRC        : 0.3616\n",
      "Brier         : 0.0468\n",
      "F1            : 0.3803\n",
      "\n",
      "Confusion matrix: (i-th truth, j-th pred)\n",
      "[[461  81]\n",
      " [  7  27]]\n"
     ]
    }
   ],
   "source": [
    "!python -u /home/nravindra/project/scnd/scripts/eval_metrics_v22.py --label SCA1_5wk --datekey 221012_122944 --eval_split test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "363071d1-f711-4d1c-9af0-faf5a84fc856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting eval...\n",
      "/home/nravindra/project/scnd/scripts/scgat_pipeline_dev.py:44: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755897462/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  indices=torch.LongTensor([coo_data.row, coo_data.col]) # OR transpose list of index tuples\n",
      "Computing METIS partitioning...\n",
      "Done!\n",
      "100%|███████████████████████████████████████████| 20/20 [00:02<00:00,  7.37it/s]\n",
      "\n",
      "Test set eval:\n",
      "  <loss>mb: 0.1344\n",
      "  <acc >mb: 0.9506\n",
      "\n",
      "SCA1_12wk results\n",
      "-----------------------\n",
      "Accuracy      : 0.9021\n",
      "Sensitivity   : 0.9474\n",
      "Specificity   : 0.9007\n",
      "\n",
      "Ave. precision: 0.5865\n",
      "Precision     : 0.9283\n",
      "Recall        : 1.0000\n",
      "\n",
      "AU-ROC        : 0.9595\n",
      "AU-PRC        : 0.5783\n",
      "Brier         : 0.0424\n",
      "F1            : 0.5556\n",
      "\n",
      "Confusion matrix: (i-th truth, j-th pred)\n",
      "[[481  53]\n",
      " [  3  35]]\n"
     ]
    }
   ],
   "source": [
    "!python -u /home/nravindra/project/scnd/scripts/eval_metrics_v22.py --label SCA1_12wk --datekey 221012_130920 --eval_split test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be66ca5f-215e-43e3-8c90-c6172c5dbccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting eval...\n",
      "/home/nravindra/project/scnd/scripts/scgat_pipeline_dev.py:44: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755897462/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  indices=torch.LongTensor([coo_data.row, coo_data.col]) # OR transpose list of index tuples\n",
      "Computing METIS partitioning...\n",
      "Done!\n",
      "100%|███████████████████████████████████████████| 20/20 [00:02<00:00,  7.54it/s]\n",
      "\n",
      "Test set eval:\n",
      "  <loss>mb: 0.2544\n",
      "  <acc >mb: 0.8896\n",
      "\n",
      "SCA1_18wk results\n",
      "-----------------------\n",
      "Accuracy      : 0.8675\n",
      "Sensitivity   : 0.9634\n",
      "Specificity   : 0.8537\n",
      "\n",
      "Ave. precision: 0.6886\n",
      "Precision     : 0.8395\n",
      "Recall        : 1.0000\n",
      "\n",
      "AU-ROC        : 0.9494\n",
      "AU-PRC        : 0.6845\n",
      "Brier         : 0.0713\n",
      "F1            : 0.6695\n",
      "\n",
      "Confusion matrix: (i-th truth, j-th pred)\n",
      "[[426  73]\n",
      " [  4  78]]\n"
     ]
    }
   ],
   "source": [
    "!python -u /home/nravindra/project/scnd/scripts/eval_metrics_v22.py --label SCA1_18wk --datekey 221012_130946 --eval_split test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d8c0436-0113-499c-9b4e-cfb0f5b1812e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting eval...\n",
      "/home/nravindra/project/scnd/scripts/scgat_pipeline_dev.py:44: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755897462/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  indices=torch.LongTensor([coo_data.row, coo_data.col]) # OR transpose list of index tuples\n",
      "Computing METIS partitioning...\n",
      "Done!\n",
      "100%|███████████████████████████████████████████| 20/20 [00:02<00:00,  7.50it/s]\n",
      "\n",
      "Test set eval:\n",
      "  <loss>mb: 0.1210\n",
      "  <acc >mb: 0.9526\n",
      "\n",
      "SCA1_24wk results\n",
      "-----------------------\n",
      "Accuracy      : 0.8895\n",
      "Sensitivity   : 1.0000\n",
      "Specificity   : 0.8859\n",
      "\n",
      "Ave. precision: 0.7497\n",
      "Precision     : 0.9512\n",
      "Recall        : 1.0000\n",
      "\n",
      "AU-ROC        : 0.9817\n",
      "AU-PRC        : 0.7451\n",
      "Brier         : 0.0217\n",
      "F1            : 0.4483\n",
      "\n",
      "Confusion matrix: (i-th truth, j-th pred)\n",
      "[[489  63]\n",
      " [  1  26]]\n"
     ]
    }
   ],
   "source": [
    "!python -u /home/nravindra/project/scnd/scripts/eval_metrics_v22.py --label SCA1_24wk --datekey 221012_131105 --eval_split test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0d72e38-661c-42ba-9fd4-0441ac4025b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting eval...\n",
      "/home/nravindra/project/scnd/scripts/scgat_pipeline_dev.py:44: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755897462/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  indices=torch.LongTensor([coo_data.row, coo_data.col]) # OR transpose list of index tuples\n",
      "Computing METIS partitioning...\n",
      "Done!\n",
      "100%|███████████████████████████████████████████| 20/20 [00:02<00:00,  8.72it/s]\n",
      "\n",
      "Test set eval:\n",
      "  <loss>mb: 0.1725\n",
      "  <acc >mb: 0.9294\n",
      "\n",
      "SCA1_30wk results\n",
      "-----------------------\n",
      "Accuracy      : 0.8752\n",
      "Sensitivity   : 0.9474\n",
      "Specificity   : 0.8663\n",
      "\n",
      "Ave. precision: 0.8185\n",
      "Precision     : 0.8555\n",
      "Recall        : 1.0000\n",
      "\n",
      "AU-ROC        : 0.9544\n",
      "AU-PRC        : 0.8172\n",
      "Brier         : 0.0486\n",
      "F1            : 0.6636\n",
      "\n",
      "Confusion matrix: (i-th truth, j-th pred)\n",
      "[[434  67]\n",
      " [  5  71]]\n"
     ]
    }
   ],
   "source": [
    "!python -u /home/nravindra/project/scnd/scripts/eval_metrics_v22.py --label SCA1_30wk --datekey 221012_143843 --eval_split test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adc2e2e4-769e-40c0-b9e3-73df34ad6eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting eval...\n",
      "/home/nravindra/project/scnd/scripts/scgat_pipeline_dev.py:44: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755897462/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  indices=torch.LongTensor([coo_data.row, coo_data.col]) # OR transpose list of index tuples\n",
      "Computing METIS partitioning...\n",
      "Done!\n",
      "100%|███████████████████████████████████████████| 20/20 [00:02<00:00,  7.55it/s]\n",
      "\n",
      "Test set eval:\n",
      "  <loss>mb: 0.4582\n",
      "  <acc >mb: 0.7723\n",
      "\n",
      "ysca1 results\n",
      "-----------------------\n",
      "Accuracy      : 0.8028\n",
      "Sensitivity   : 0.7790\n",
      "Specificity   : 0.8272\n",
      "\n",
      "Ave. precision: 0.8685\n",
      "Precision     : 0.4595\n",
      "Recall        : 1.0000\n",
      "\n",
      "AU-ROC        : 0.8769\n",
      "AU-PRC        : 0.8682\n",
      "Brier         : 0.1473\n",
      "F1            : 0.7871\n",
      "\n",
      "Confusion matrix: (i-th truth, j-th pred)\n",
      "[[249  52]\n",
      " [ 60 207]]\n"
     ]
    }
   ],
   "source": [
    "!python -u /home/nravindra/project/scnd/scripts/eval_metrics_v22.py --label ysca1 --datekey 221012_110419 --eval_split test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7357cf4-4999-410b-8e56-a889d81b9e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting eval...\n",
      "/home/nravindra/project/scnd/scripts/scgat_pipeline_dev.py:44: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755897462/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  indices=torch.LongTensor([coo_data.row, coo_data.col]) # OR transpose list of index tuples\n",
      "Computing METIS partitioning...\n",
      "Done!\n",
      "100%|███████████████████████████████████████████| 20/20 [00:02<00:00,  7.59it/s]\n",
      "\n",
      "Test set eval:\n",
      "  <loss>mb: 1.3807\n",
      "  <acc >mb: 0.5101\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nravindra/project/scnd/scripts/eval_metrics_v22.py\", line 113, in <module>\n",
      "    fpr, tpr, thresholds = metrics.roc_curve(y_true, p1)\n",
      "  File \"/home/nravindra/miniconda3/envs/scnd2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 981, in roc_curve\n",
      "    fps, tps, thresholds = _binary_clf_curve(\n",
      "  File \"/home/nravindra/miniconda3/envs/scnd2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 740, in _binary_clf_curve\n",
      "    raise ValueError(\"{0} format is not supported\".format(y_type))\n",
      "ValueError: multiclass format is not supported\n"
     ]
    }
   ],
   "source": [
    "!python -u /home/nravindra/project/scnd/scripts/eval_metrics_v22.py --label ygenotime --datekey 221012_145251 --eval_split test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cae3e83-ce19-4201-bdd3-4d02193d682b",
   "metadata": {},
   "source": [
    "# try on val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1940ca9c-21f6-4f90-9269-1a000e4860aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting eval...\n",
      "/home/nravindra/project/scnd/scripts/scgat_pipeline_dev.py:44: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755897462/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  indices=torch.LongTensor([coo_data.row, coo_data.col]) # OR transpose list of index tuples\n",
      "Computing METIS partitioning...\n",
      "Done!\n",
      "100%|███████████████████████████████████████████| 20/20 [00:02<00:00,  7.91it/s]\n",
      "\n",
      "Test set eval:\n",
      "  <loss>mb: 0.1488\n",
      "  <acc >mb: 0.9433\n",
      "\n",
      "SCA1_5wk results\n",
      "-----------------------\n",
      "Accuracy      : 0.8633\n",
      "Sensitivity   : 0.9500\n",
      "Specificity   : 0.8587\n",
      "\n",
      "Ave. precision: 0.5665\n",
      "Precision     : 0.9244\n",
      "Recall        : 1.0000\n",
      "\n",
      "AU-ROC        : 0.9429\n",
      "AU-PRC        : 0.5590\n",
      "Brier         : 0.0408\n",
      "F1            : 0.4837\n",
      "\n",
      "Confusion matrix: (i-th truth, j-th pred)\n",
      "[[462  76]\n",
      " [  3  37]]\n"
     ]
    }
   ],
   "source": [
    "!python -u /home/nravindra/project/scnd/scripts/eval_metrics_v22.py --label SCA1_5wk --datekey 221012_122944 --eval_split val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b95ae270-eee7-44fa-a3d4-b77b8a2efcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting eval...\n",
      "/home/nravindra/project/scnd/scripts/scgat_pipeline_dev.py:44: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755897462/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  indices=torch.LongTensor([coo_data.row, coo_data.col]) # OR transpose list of index tuples\n",
      "Computing METIS partitioning...\n",
      "Done!\n",
      "100%|███████████████████████████████████████████| 20/20 [00:02<00:00,  7.29it/s]\n",
      "\n",
      "Test set eval:\n",
      "  <loss>mb: 0.1374\n",
      "  <acc >mb: 0.9501\n",
      "\n",
      "SCA1_12wk results\n",
      "-----------------------\n",
      "Accuracy      : 0.8813\n",
      "Sensitivity   : 0.9111\n",
      "Specificity   : 0.8807\n",
      "\n",
      "Ave. precision: 0.5847\n",
      "Precision     : 0.9148\n",
      "Recall        : 1.0000\n",
      "\n",
      "AU-ROC        : 0.9448\n",
      "AU-PRC        : 0.5774\n",
      "Brier         : 0.0473\n",
      "F1            : 0.5405\n",
      "\n",
      "Confusion matrix: (i-th truth, j-th pred)\n",
      "[[465  63]\n",
      " [  5  40]]\n"
     ]
    }
   ],
   "source": [
    "!python -u /home/nravindra/project/scnd/scripts/eval_metrics_v22.py --label SCA1_12wk --datekey 221012_130920 --eval_split val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47780ba1-d30c-424a-a454-bac7f1bfab60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting eval...\n",
      "/home/nravindra/project/scnd/scripts/scgat_pipeline_dev.py:44: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755897462/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  indices=torch.LongTensor([coo_data.row, coo_data.col]) # OR transpose list of index tuples\n",
      "Computing METIS partitioning...\n",
      "Done!\n",
      "100%|███████████████████████████████████████████| 20/20 [00:02<00:00,  8.05it/s]\n",
      "\n",
      "Test set eval:\n",
      "  <loss>mb: 0.2722\n",
      "  <acc >mb: 0.8835\n",
      "\n",
      "SCA1_18wk results\n",
      "-----------------------\n",
      "Accuracy      : 0.8599\n",
      "Sensitivity   : 0.9667\n",
      "Specificity   : 0.8341\n",
      "\n",
      "Ave. precision: 0.8128\n",
      "Precision     : 0.7600\n",
      "Recall        : 1.0000\n",
      "\n",
      "AU-ROC        : 0.9525\n",
      "AU-PRC        : 0.8118\n",
      "Brier         : 0.0832\n",
      "F1            : 0.7395\n",
      "\n",
      "Confusion matrix: (i-th truth, j-th pred)\n",
      "[[382  76]\n",
      " [  5 115]]\n"
     ]
    }
   ],
   "source": [
    "!python -u /home/nravindra/project/scnd/scripts/eval_metrics_v22.py --label SCA1_18wk --datekey 221012_130946 --eval_split val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1251d4dd-5549-4a2c-a92e-9493c182dc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting eval...\n",
      "/home/nravindra/project/scnd/scripts/scgat_pipeline_dev.py:44: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755897462/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  indices=torch.LongTensor([coo_data.row, coo_data.col]) # OR transpose list of index tuples\n",
      "Computing METIS partitioning...\n",
      "Done!\n",
      "100%|███████████████████████████████████████████| 20/20 [00:02<00:00,  7.55it/s]\n",
      "\n",
      "Test set eval:\n",
      "  <loss>mb: 0.1234\n",
      "  <acc >mb: 0.9481\n",
      "\n",
      "SCA1_24wk results\n",
      "-----------------------\n",
      "Accuracy      : 0.9284\n",
      "Sensitivity   : 0.8684\n",
      "Specificity   : 0.9346\n",
      "\n",
      "Ave. precision: 0.6451\n",
      "Precision     : 0.9305\n",
      "Recall        : 1.0000\n",
      "\n",
      "AU-ROC        : 0.9562\n",
      "AU-PRC        : 0.6438\n",
      "Brier         : 0.0462\n",
      "F1            : 0.6095\n",
      "\n",
      "Confusion matrix: (i-th truth, j-th pred)\n",
      "[[500  35]\n",
      " [  6  32]]\n"
     ]
    }
   ],
   "source": [
    "!python -u /home/nravindra/project/scnd/scripts/eval_metrics_v22.py --label SCA1_24wk --datekey 221012_131105 --eval_split val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49a76135-12e7-492c-92c2-dc3b7b48d603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting eval...\n",
      "/home/nravindra/project/scnd/scripts/scgat_pipeline_dev.py:44: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755897462/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  indices=torch.LongTensor([coo_data.row, coo_data.col]) # OR transpose list of index tuples\n",
      "Computing METIS partitioning...\n",
      "Done!\n",
      "100%|███████████████████████████████████████████| 20/20 [00:02<00:00,  8.64it/s]\n",
      "\n",
      "Test set eval:\n",
      "  <loss>mb: 0.1728\n",
      "  <acc >mb: 0.9284\n",
      "\n",
      "SCA1_30wk results\n",
      "-----------------------\n",
      "Accuracy      : 0.9017\n",
      "Sensitivity   : 0.9565\n",
      "Specificity   : 0.8943\n",
      "\n",
      "Ave. precision: 0.6837\n",
      "Precision     : 0.8698\n",
      "Recall        : 1.0000\n",
      "\n",
      "AU-ROC        : 0.9571\n",
      "AU-PRC        : 0.6816\n",
      "Brier         : 0.0566\n",
      "F1            : 0.6952\n",
      "\n",
      "Confusion matrix: (i-th truth, j-th pred)\n",
      "[[458  53]\n",
      " [  4  65]]\n"
     ]
    }
   ],
   "source": [
    "!python -u /home/nravindra/project/scnd/scripts/eval_metrics_v22.py --label SCA1_30wk --datekey 221012_143843 --eval_split val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "621d1e00-e11e-4b41-ab31-11bfe9e09a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting eval...\n",
      "/home/nravindra/project/scnd/scripts/scgat_pipeline_dev.py:44: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755897462/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  indices=torch.LongTensor([coo_data.row, coo_data.col]) # OR transpose list of index tuples\n",
      "Computing METIS partitioning...\n",
      "Done!\n",
      "100%|███████████████████████████████████████████| 20/20 [00:02<00:00,  7.56it/s]\n",
      "\n",
      "Test set eval:\n",
      "  <loss>mb: 0.4836\n",
      "  <acc >mb: 0.7512\n",
      "\n",
      "ysca1 results\n",
      "-----------------------\n",
      "Accuracy      : 0.7778\n",
      "Sensitivity   : 0.7439\n",
      "Specificity   : 0.8153\n",
      "\n",
      "Ave. precision: 0.8609\n",
      "Precision     : 0.4148\n",
      "Recall        : 0.9862\n",
      "\n",
      "AU-ROC        : 0.8633\n",
      "AU-PRC        : 0.8606\n",
      "Brier         : 0.1638\n",
      "F1            : 0.7698\n",
      "\n",
      "Confusion matrix: (i-th truth, j-th pred)\n",
      "[[234  53]\n",
      " [ 75 214]]\n"
     ]
    }
   ],
   "source": [
    "!python -u /home/nravindra/project/scnd/scripts/eval_metrics_v22.py --label ysca1 --datekey 221012_110419 --eval_split val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20dffdc-1213-4d79-a97e-b8bd7292a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -u /home/nravindra/project/scnd/scripts/eval_metrics_v22.py --label ygenotime --datekey 221012_110419 --eval_split val\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Grab data from AnnData object and use it to create a graph pkl\n",
    "\n",
    "## Background\n",
    "\n",
    "Data can be represented in a more complete way by utilizing edge features in graph attention networks. \n",
    "\n",
    "## Objective\n",
    "\n",
    "Use self-supervised learning to learn graphical representations of data and harness edge features in improving performance of predictive tasks\n",
    "\n",
    "## Methods\n",
    "\n",
    "GAT, edge features, self-supervised learning, representation learning, healthcare application, single-cell transcriptomic data\n",
    "\n",
    "- val/test are equivalent here so we report performance on val set, since care only about what the network learns internally and use this for interpretability\n",
    "\n",
    "## Results\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "## Future directions\n",
    "\n",
    "- use batch labels from dataset, train GAT to get edge coefficients from preds of those labels, use this for \"batch effect correction\" in the model, either by penalizing reliance on these edge features, or controlling for them in the final model \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext memory_profiler\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import pickle\n",
    "import scanpy as sc\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sc.settings.verbosity=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load AnnData obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded @200528.22:25:09\n",
      "took 79.43-s to load data\n",
      "peak memory: 74841.77 MiB, increment: 74658.86 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/ycga/project/dijk/ngr4/conda_envs/rnavel/lib/python3.7/site-packages/anndata/compat/__init__.py:161: FutureWarning: Moving element from .uns['neighbors']['distances'] to .obsp['distances'].\n",
      "\n",
      "This is where adjacency matrices should go now.\n",
      "  FutureWarning,\n",
      "/gpfs/ycga/project/dijk/ngr4/conda_envs/rnavel/lib/python3.7/site-packages/anndata/compat/__init__.py:161: FutureWarning: Moving element from .uns['neighbors']['connectivities'] to .obsp['connectivities'].\n",
      "\n",
      "This is where adjacency matrices should go now.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# fps\n",
    "pfp = '/home/ngr4/project/scnd/results/'\n",
    "pdfp = '/home/ngr4/project/scnd/data/processed/'\n",
    "\n",
    "def loader(fname,fpath,backed=None) : \n",
    "    start = time.time()\n",
    "    adata = sc.read_h5ad(filename=os.path.join(fpath,fname),backed=backed)\n",
    "    print('loaded @'+datetime.datetime.now().strftime('%y%m%d.%H:%M:%S'))\n",
    "    print('took {:.2f}-s to load data'.format(time.time()-start))\n",
    "    return adata\n",
    "\n",
    "def writer(fname,fpath,AnnData) :\n",
    "    start = time.time()\n",
    "    Anndata.write(os.path.join(fpath,fname))\n",
    "    print('saved @'+datetime.datetime.now().strftime('%y%m%d.%H:%M:%S'))\n",
    "    print('took {:.2f}-s to save data'.format(time.time()-start))\n",
    "    \n",
    "\n",
    "if False :\n",
    "    # load human\n",
    "    fname='hum_MT_bbknn.h5ad'\n",
    "    %memit hdata = loader(fname,pdfp)\n",
    "    \n",
    "if True :\n",
    "    # load mouse\n",
    "    fname='mouse_MT_bbknn.h5ad'\n",
    "    %memit adata = loader(fname,pdfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Induction\n",
    "\n",
    "Sample 1/3 of the data randomly, grab labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 83275.46 MiB, increment: 4650.95 MiB\n",
      "computing PCA\n",
      "    with n_comps=50\n",
      "    finished (0:02:55)\n",
      "computing batch balanced neighbors\n",
      "\tfinished (0:02:27)\n",
      "computing PCA\n",
      "    with n_comps=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/ycga/project/dijk/ngr4/conda_envs/rnavel/lib/python3.7/site-packages/bbknn/__init__.py:294: FutureWarning: This location for 'distances' is deprecated. It has been moved to .obsp[distances], and will not be accesible here in a future version of anndata.\n",
      "  adata.uns['neighbors']['distances'] = bbknn_out[0]\n",
      "/gpfs/ycga/project/dijk/ngr4/conda_envs/rnavel/lib/python3.7/site-packages/bbknn/__init__.py:295: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.\n",
      "  adata.uns['neighbors']['connectivities'] = bbknn_out[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:01:11)\n",
      "computing batch balanced neighbors\n",
      "\tfinished (0:00:25)\n",
      "computing PCA\n",
      "    with n_comps=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/ycga/project/dijk/ngr4/conda_envs/rnavel/lib/python3.7/site-packages/bbknn/__init__.py:294: FutureWarning: This location for 'distances' is deprecated. It has been moved to .obsp[distances], and will not be accesible here in a future version of anndata.\n",
      "  adata.uns['neighbors']['distances'] = bbknn_out[0]\n",
      "/gpfs/ycga/project/dijk/ngr4/conda_envs/rnavel/lib/python3.7/site-packages/bbknn/__init__.py:295: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.\n",
      "  adata.uns['neighbors']['connectivities'] = bbknn_out[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:01:14)\n",
      "computing batch balanced neighbors\n",
      "\tfinished (0:00:25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/ycga/project/dijk/ngr4/conda_envs/rnavel/lib/python3.7/site-packages/bbknn/__init__.py:294: FutureWarning: This location for 'distances' is deprecated. It has been moved to .obsp[distances], and will not be accesible here in a future version of anndata.\n",
      "  adata.uns['neighbors']['distances'] = bbknn_out[0]\n",
      "/gpfs/ycga/project/dijk/ngr4/conda_envs/rnavel/lib/python3.7/site-packages/bbknn/__init__.py:295: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.\n",
      "  adata.uns['neighbors']['connectivities'] = bbknn_out[1]\n"
     ]
    }
   ],
   "source": [
    "# sample the data \n",
    "idx_train, idx_test = train_test_split(adata.obs.index, train_size=0.33)\n",
    "%memit tdata = sc.AnnData(X=adata[adata.obs.index.isin(idx_train),:].X, obs=adata[adata.obs.index.isin(idx_train),:].obs)\n",
    "temp = adata.obs.index[adata.obs.index.isin(idx_test)].to_list()\n",
    "idx_val, idx_test = train_test_split(temp, train_size=0.1)\n",
    "val = sc.AnnData(X=adata[adata.obs.index.isin(idx_val),:].X, obs=adata[adata.obs.index.isin(idx_val),:].obs)\n",
    "temp = adata.obs.index[adata.obs.index.isin(idx_test)].to_list()\n",
    "idx_test, _ = train_test_split(temp, train_size=0.11)\n",
    "test = sc.AnnData(X=adata[adata.obs.index.isin(idx_test),:].X, obs=adata[adata.obs.index.isin(idx_test),:].obs)\n",
    "\n",
    "def graph_pp(AnnData, bbknn=True):\n",
    "    sc.tl.pca(AnnData, n_comps=50)\n",
    "    if bbknn:\n",
    "        sc.external.pp.bbknn(AnnData)\n",
    "    else:\n",
    "        sc.pp.neighbors(AnnData, n_pcs=100, n_neighbors=30)\n",
    "    return AnnData\n",
    "\n",
    "# make graph\n",
    "tdata = graph_pp(tdata)\n",
    "val = graph_pp(val)\n",
    "test = graph_pp(test)\n",
    "\n",
    "if False:\n",
    "    del adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding \n",
    "\n",
    "Select tasks for prediction\n",
    "\n",
    "1. yctype\n",
    "2. ysca1\n",
    "3. ygenotime (already done)\n",
    "4. SCA1_5/12/18/24/30wk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode ctype \n",
    "ctype_encoder = {v:i for i,v in enumerate(tdata.obs['ctype'].unique())}\n",
    "tdata.obs['yctype'] = tdata.obs['ctype'].map(ctype_encoder)\n",
    "val.obs['yctype'] = val.obs['ctype'].map(ctype_encoder)\n",
    "test.obs['yctype'] = test.obs['ctype'].map(ctype_encoder)\n",
    "\n",
    "# encode WT/SCA1 blended across time\n",
    "genotype_encoder = {'WT':0, 'SCA1':1}\n",
    "tdata.obs['ysca1'] = tdata.obs['genotype'].map(genotype_encoder).astype(int)\n",
    "val.obs['ysca1'] = val.obs['genotype'].map(genotype_encoder).astype(int)\n",
    "test.obs['ysca1'] = test.obs['genotype'].map(genotype_encoder).astype(int)\n",
    "\n",
    "# encode multi-label\n",
    "tdata.obs['genotype_timepoint'] = tdata.obs['genotype'].astype(str) + tdata.obs['timepoint'].astype(str).apply(lambda x: '_{}'.format(x))\n",
    "val.obs['genotype_timepoint'] = val.obs['genotype'].astype(str) + val.obs['timepoint'].astype(str).apply(lambda x: '_{}'.format(x))\n",
    "test.obs['genotype_timepoint'] = test.obs['genotype'].astype(str) + test.obs['timepoint'].astype(str).apply(lambda x: '_{}'.format(x))\n",
    "\n",
    "gt_encoder = {v:i for i,v in enumerate(tdata.obs['genotype_timepoint'].unique())}\n",
    "tdata.obs['ygenotime'] = tdata.obs['genotype_timepoint'].map(gt_encoder)\n",
    "val.obs['ygenotime'] = val.obs['genotype_timepoint'].map(gt_encoder)\n",
    "test.obs['ygenotime'] = test.obs['genotype_timepoint'].map(gt_encoder)\n",
    "\n",
    "# encode distinguishability of SCA1 at specific timepoints \n",
    "verbose = False\n",
    "tdata.obs['SCA1_5wk'] = (tdata.obs['genotype_timepoint']=='SCA1_5wk').astype(int)\n",
    "tdata.obs['SCA1_12wk'] = (tdata.obs['genotype_timepoint']=='SCA1_12wk').astype(int)\n",
    "tdata.obs['SCA1_18wk'] = (tdata.obs['genotype_timepoint']=='SCA1_18wk').astype(int)\n",
    "tdata.obs['SCA1_24wk'] = (tdata.obs['genotype_timepoint']=='SCA1_24wk').astype(int)\n",
    "tdata.obs['SCA1_30wk'] = (tdata.obs['genotype_timepoint']=='SCA1_30wk').astype(int)\n",
    "val.obs['SCA1_5wk'] = (val.obs['genotype_timepoint']=='SCA1_5wk').astype(int)\n",
    "val.obs['SCA1_12wk'] = (val.obs['genotype_timepoint']=='SCA1_12wk').astype(int)\n",
    "val.obs['SCA1_18wk'] = (val.obs['genotype_timepoint']=='SCA1_18wk').astype(int)\n",
    "val.obs['SCA1_24wk'] = (val.obs['genotype_timepoint']=='SCA1_24wk').astype(int)\n",
    "val.obs['SCA1_30wk'] = (val.obs['genotype_timepoint']=='SCA1_30wk').astype(int)\n",
    "test.obs['SCA1_5wk'] = (test.obs['genotype_timepoint']=='SCA1_5wk').astype(int)\n",
    "test.obs['SCA1_12wk'] = (test.obs['genotype_timepoint']=='SCA1_12wk').astype(int)\n",
    "test.obs['SCA1_18wk'] = (test.obs['genotype_timepoint']=='SCA1_18wk').astype(int)\n",
    "test.obs['SCA1_24wk'] = (test.obs['genotype_timepoint']=='SCA1_24wk').astype(int)\n",
    "test.obs['SCA1_30wk'] = (test.obs['genotype_timepoint']=='SCA1_30wk').astype(int)\n",
    "\n",
    "verbose = False\n",
    "if verbose:\n",
    "    # check encoding \n",
    "    print(tdata.obs['genotype_timepoint'].value_counts())\n",
    "    for i in ['SCA1_5wk', 'SCA1_12wk','SCA1_18wk','SCA1_24wk','SCA1_30wk']:\n",
    "        print(tdata.obs[i].sum())\n",
    "        \n",
    "    print(test.obs['genotype_timepoint'].value_counts())\n",
    "    for i in ['SCA1_5wk', 'SCA1_12wk','SCA1_18wk','SCA1_24wk','SCA1_30wk']:\n",
    "        print(test.obs[i].sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/ycga/project/dijk/ngr4/conda_envs/rnavel/lib/python3.7/site-packages/ipykernel_launcher.py:32: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.\n",
      "/gpfs/ycga/project/dijk/ngr4/conda_envs/rnavel/lib/python3.7/site-packages/ipykernel_launcher.py:32: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.\n",
      "/gpfs/ycga/project/dijk/ngr4/conda_envs/rnavel/lib/python3.7/site-packages/ipykernel_launcher.py:32: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.\n"
     ]
    }
   ],
   "source": [
    "# create dictionary\n",
    "def dictthat(AnnData, gene_ranger=True):\n",
    "    \"\"\"Prep dictionary for export.\n",
    "    \n",
    "    If gene_ranger, divide by zero can occur for \n",
    "    non-expressing genes. Thus, will floor those\n",
    "    to 0.\n",
    "    \n",
    "    NOTE: customization re:y to predict is highly\n",
    "    dependent on user input. ERGO, modify this \n",
    "    \n",
    "    Arguments:\n",
    "        AnnData (sc.AnnData): with graph stuff\n",
    "        \n",
    "    Returns:\n",
    "        dict\n",
    "    \"\"\"\n",
    "    if gene_ranger:\n",
    "        # each gene in [0,1], divide by zeros to 0\n",
    "        minimum = AnnData.X.min(axis=0)\n",
    "        maximum = AnnData.X.max(axis=0)\n",
    "        num = AnnData.X - minimum.todense()\n",
    "        denom =  (maximum - minimum).todense()\n",
    "        xhat = np.divide(num, denom, out=np.zeros_like(num), where=denom!=0) \n",
    "    else:\n",
    "        # matrix in [0,1]\n",
    "        xhat = (AnnData.X - AnnData.X.min()) / (AnnData.X.max() - AnnData.X.min())\n",
    "        \n",
    "    \n",
    "\n",
    "    gdata = {'X':xhat,\n",
    "             'adj':AnnData.uns['neighbors']['connectivities']+sparse.diags([1]*AnnData.shape[0], format='csr'),\n",
    "             'feature_names':AnnData.var_names.to_list()}\n",
    "    gdata['cell_id'] = AnnData.obs.index.to_list()\n",
    "    for col in AnnData.obs.columns:\n",
    "        gdata[col] = AnnData.obs[col].to_list()\n",
    "    \n",
    "    return gdata\n",
    "\n",
    "gdata_train = dictthat(tdata)\n",
    "gdata_val = dictthat(val)\n",
    "gdata_test  = dictthat(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def pklthat(gdata, fname, fpath=pdfp): \n",
    "    with open(os.path.join(fpath,fname),'wb') as f :\n",
    "        pickle.dump(gdata, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        f.close()\n",
    "\n",
    "pklthat(gdata_train, 'scnd_train_200528.pkl')\n",
    "pklthat(gdata_val, 'scnd_val_200528.pkl')\n",
    "pklthat(gdata_test, 'scnd_test_200528.pkl')\n",
    "\n",
    "# clean\n",
    "if True:\n",
    "    del tdata, test, gdata_train, gdata_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modify pkl\n",
    "\n",
    "Add batch encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadpkl(filename):\n",
    "    with open (filename, 'rb') as f:\n",
    "        temp = pickle.load(f)\n",
    "        f.close()\n",
    "    return temp\n",
    "\n",
    "def add_batch(filename, date='200529'):\n",
    "    gdata = loadpkl(filename)\n",
    "    batch_encoder = {v:i for i,v in enumerate(np.unique(gdata['batch']))}\n",
    "    gdata['ybatch'] = list(map(batch_encoder.get, gdata['batch']))\n",
    "    pklthat(gdata, '{}_{}.pkl'.format(os.path.split(filename)[1].split('_20')[0], date))\n",
    "    del gdata\n",
    "    print('Batch added and pkl saved:\\n  {}_{}.pkl'.format(os.path.split(filename)[1].split('_20')[0], date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch added and pkl saved:\n",
      "  scnd_train.pkl\n",
      "Batch added and pkl saved:\n",
      "  scnd_val.pkl\n",
      "Batch added and pkl saved:\n",
      "  scnd_test.pkl\n"
     ]
    }
   ],
   "source": [
    "add_batch(os.path.join(pdfp,'scnd_train_200528.pkl'))\n",
    "add_batch(os.path.join(pdfp,'scnd_val_200528.pkl'))\n",
    "add_batch(os.path.join(pdfp,'scnd_test_200528.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "gdata = loadpkl(os.path.join(pdfp,'scnd_train_200529.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
